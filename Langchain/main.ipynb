{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "619ec6e3-0b8a-4a73-9899-011816856c8b",
   "metadata": {},
   "source": [
    "# 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac019a2-a9ce-4e2e-b68c-3e3dae2ce14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9af6f8-1f8c-42af-8dfc-00c09efbb864",
   "metadata": {},
   "source": [
    "# 2. Import LLM API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6566d313-bc4f-46f3-8689-c92bf1d0daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DASHSCOPE_API_KEY = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "\n",
    "if not DASHSCOPE_API_KEY:\n",
    "    raise ValueError(\"è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® DASHSCOPE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea6a7fa-13b9-4e66-9ad5-aa2ad12ea6f8",
   "metadata": {},
   "source": [
    "# 3. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0950b0-c977-4575-b6bf-36d0091362bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å…±åŠ è½½ 606 ç¯‡è¯ˆéª—æ–°é—»\n"
     ]
    }
   ],
   "source": [
    "file_path = \"hk01_scam_articles.md\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# æŒ‰ \"---\" åˆ†å‰²æ–‡ç« ï¼ˆæ”¯æŒå‰åæœ‰ç©ºè¡Œï¼‰\n",
    "articles = [a.strip() for a in re.split(r'\\n-{3,}\\n', content) if a.strip()]\n",
    "\n",
    "print(f\"âœ… å…±åŠ è½½ {len(articles)} ç¯‡è¯ˆéª—æ–°é—»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ad63c0-12d3-410f-aba1-a9a5d558449e",
   "metadata": {},
   "source": [
    "# 4. Converting data to document format makes it easier to store in the Chroma database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e800f6-4d22-4b71-ad36-606f82af7dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ ç¤ºä¾‹æ ‡é¢˜: [2. ç¶²ä¸Šæƒ…ç·£é¨™æ¡ˆï½œæ‰®å¥³äººæ°¹è½ç–Šç¨±è´ˆéºç”¢ã€€å†’è­¦äºŒæ¬¡è©é¨™ã€€å…±å‘ƒ4400è¬](https://www.hk01.com/çªç™¼/60318574/ç¶²ä¸Šæƒ…ç·£é¨™æ¡ˆ-æ‰®å¥³äººæ°¹è½ç–Šç¨±è´ˆéºç”¢-å†’è­¦äºŒæ¬¡è©é¨™-å…±å‘ƒ4400è¬)\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for i, art in enumerate(articles):\n",
    "    lines = art.splitlines()\n",
    "    # æå–æ ‡é¢˜ï¼šå–ç¬¬ä¸€è¡Œï¼Œå»æ‰å¯èƒ½çš„ Markdown æ ‡é¢˜ç¬¦å·ï¼ˆå¦‚ ###ã€##ã€#ï¼‰\n",
    "    if lines:\n",
    "        title_line = lines[0].strip()\n",
    "        # ç§»é™¤å¼€å¤´çš„ # ç¬¦å·å’Œç©ºæ ¼\n",
    "        title = re.sub(r'^#+\\s*', '', title_line)\n",
    "    else:\n",
    "        title = f\"æ–‡ç«  #{i+1}\"\n",
    "    \n",
    "    doc = Document(\n",
    "        page_content=art,\n",
    "        metadata={\n",
    "            \"source\": file_path,\n",
    "            \"article_id\": i + 1,\n",
    "            \"title\": title\n",
    "            # æ³¨æ„ï¼šæ²¡æœ‰ date å­—æ®µ\n",
    "        }\n",
    "    )\n",
    "    docs.append(doc)\n",
    "\n",
    "print(\"ğŸ“„ ç¤ºä¾‹æ ‡é¢˜:\", docs[1].metadata[\"title\"] if docs else \"æ— \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea80d84e-4af2-4b85-87a2-81a9a933e197",
   "metadata": {},
   "source": [
    "# 5. Build a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eeef41f-b084-41bb-9ec4-1767ba542cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalEmbeddings:\n",
    "    def __init__(self, model_name=\"shibing624/text2vec-base-chinese\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode(texts, normalize_embeddings=True).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode([text], normalize_embeddings=True)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c810e740-9232-4a6a-832d-633f5fb448e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199/199 [00:00<00:00, 654.61it/s, Materializing param=pooler.dense.weight]\n",
      "BertModel LOAD REPORT from: shibing624/text2vec-base-chinese\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å†™å…¥åæ–‡æ¡£æ€»æ•°: 606\n"
     ]
    }
   ],
   "source": [
    "embeddings = LocalEmbeddings()\n",
    "# æ„å»ºå‘é‡åº“ï¼ˆä½¿ç”¨ä½ å·²å®šä¹‰çš„ LocalEmbeddingsï¼‰\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    embeddings,  # â† ä½ ä¹‹å‰çš„ LocalEmbeddings å®ä¾‹\n",
    "    persist_directory=\"./chroma_hk01_scam_db\"  # å»ºè®®æ–°å»ºç›®å½•ï¼Œé¿å…æ··æ·†\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "print(f\"å†™å…¥åæ–‡æ¡£æ€»æ•°: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482352c-56da-4ef9-b8c7-1dd3d8c255b7",
   "metadata": {},
   "source": [
    "# 6. Configure LLM and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b6ab9a1-6e16-43e1-a8b4-80f2a65ab5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek-v3.2\",\n",
    "    openai_api_key=DASHSCOPE_API_KEY,\n",
    "    openai_api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6150fd9b-5746-4c76-9fbf-e916e9e8e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "ä½ æ˜¯ä¸€ååè¯ˆä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹çŸ­ä¿¡å†…å®¹å’Œè¿‘æœŸçœŸå®è¯ˆéª—æ–°é—»æ¡ˆä¾‹ï¼Œåˆ¤æ–­è¯¥çŸ­ä¿¡æ˜¯å¦å±äºå·²çŸ¥è¯ˆéª—æ¨¡å¼ã€‚\n",
    "\n",
    "çŸ­ä¿¡å†…å®¹ï¼š\n",
    "{sms}\n",
    "\n",
    "ç›¸å…³è¿‘æœŸè¯ˆéª—æ–°é—»ï¼ˆæ¥è‡ª HK01ï¼‰ï¼š\n",
    "{retrieved_cases}\n",
    "\n",
    "è¯·é‡ç‚¹åˆ†æï¼š\n",
    "- æ˜¯å¦æ¶‰åŠç›¸åŒè¯æœ¯ï¼ˆå¦‚â€œéªŒè¯èº«ä»½â€ã€â€œç´§æ€¥è½¬è´¦â€ã€â€œä¸­å¥–â€ç­‰ï¼‰\n",
    "- æ˜¯å¦æ¨¡ä»¿å®˜æ–¹æœºæ„ï¼ˆé“¶è¡Œã€å…¬å®‰ã€å¿«é€’ï¼‰\n",
    "- æ˜¯å¦è¯±å¯¼ç‚¹å‡»é“¾æ¥/ä¸‹è½½APP/æä¾›éªŒè¯ç \n",
    "\n",
    "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š\n",
    "{{\"score\": æ•´æ•°ï¼ˆ0-10ï¼‰, \"reason\": \"ç®€è¦ç†ç”±ï¼ˆ50å­—å†…ï¼‰\"}}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5af879-3abe-4148-ae62-f4b4fc438c4d",
   "metadata": {},
   "source": [
    "# 7. Configure RAG + LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11081995-64d1-47fc-a85c-f09cbad203d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fraud_probability(sms_text: str) -> tuple[float, str]:\n",
    "    retrieved_docs = retriever.invoke(sms_text)\n",
    "    cases = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    formatted_prompt = prompt.format(sms=sms_text, retrieved_cases=cases)\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    output = response.content.strip()\n",
    "    \n",
    "    try:\n",
    "        # å°è¯•è§£æ JSON\n",
    "        result = json.loads(output)\n",
    "        score = int(result[\"score\"])\n",
    "        reason = result.get(\"reason\", \"æ— ç†ç”±\").strip()\n",
    "        score = max(0, min(10, score))\n",
    "        probability = score / 10.0\n",
    "        return probability, reason\n",
    "    except Exception as e:\n",
    "        # fallbackï¼šä»æ–‡æœ¬ä¸­æå–æ•°å­—å’Œç†ç”±\n",
    "        numbers = re.findall(r'\\d+', output)\n",
    "        score = int(numbers[0]) if numbers else 5\n",
    "        score = max(0, min(10, score))\n",
    "        probability = score / 10.0\n",
    "        \n",
    "        # æå–ç†ç”±ï¼ˆæ‰¾å†’å·/å¼•å·åçš„å†…å®¹ï¼‰\n",
    "        reason_match = re.search(r'(?<=[ï¼š:\"])([^\"]+?)(?=\"|$)', output)\n",
    "        if reason_match:\n",
    "            reason = reason_match.group(1).strip()[:60]\n",
    "        else:\n",
    "            reason = f\"ï¼ˆLLM è¿”å›ï¼š{output[:30]}...ï¼‰\"\n",
    "        \n",
    "        return probability, reason"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8a8e8-8db1-49ad-97fb-9524b9027030",
   "metadata": {},
   "source": [
    "# 8. Configure LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6824ea84-7e7b-4fbf-a361-fd4b123c017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fraud_probability_baseline(sms_text: str) -> tuple[float, str]:\n",
    "    \"\"\"\n",
    "    çº¯ DeepSeek-v3.2 åˆ¤æ–­ï¼ˆæ—  RAGï¼‰ï¼Œä½¿ç”¨ä¸ RAG ç‰ˆæœ¬å®Œå…¨ç›¸åŒçš„ Prompt å’Œè§£æé€»è¾‘\n",
    "    \"\"\"\n",
    "    # âš ï¸ æ³¨æ„ï¼šè¿™é‡Œä¸å†è°ƒç”¨ retrieverï¼Œretrieved_cases å›ºå®šä¸º \"æ— \"\n",
    "    formatted_prompt = prompt.format(sms=sms_text, retrieved_cases=\"æ— \")\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    output = response.content.strip()\n",
    "\n",
    "    try:\n",
    "        # å°è¯•è§£æ JSON\n",
    "        result = json.loads(output)\n",
    "        score = int(result[\"score\"])\n",
    "        reason = result.get(\"reason\", \"æ— ç†ç”±\").strip()\n",
    "        score = max(0, min(10, score))\n",
    "        probability = score / 10.0\n",
    "        return probability, reason\n",
    "    except Exception as e:\n",
    "        # fallbackï¼šä»æ–‡æœ¬ä¸­æå–æ•°å­—å’Œç†ç”±\n",
    "        numbers = re.findall(r'\\d+', output)\n",
    "        score = int(numbers[0]) if numbers else 5\n",
    "        score = max(0, min(10, score))\n",
    "        probability = score / 10.0\n",
    "\n",
    "        # æå–ç†ç”±ï¼ˆæ‰¾å†’å·/å¼•å·åçš„å†…å®¹ï¼‰\n",
    "        reason_match = re.search(r'(?<=[ï¼š:\"])([^\"]+?)(?=\"|$)', output)\n",
    "        if reason_match:\n",
    "            reason = reason_match.group(1).strip()[:60]\n",
    "        else:\n",
    "            reason = f\"ï¼ˆLLM è¿”å›ï¼š{output[:30]}...ï¼‰\"\n",
    "\n",
    "        return probability, reason"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8807d-d37e-4af3-9f73-cf6970b99867",
   "metadata": {},
   "source": [
    "# 9. Test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c498394b-e049-4206-841b-5c9437be0f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "çŸ­ä¿¡å†…å®¹ï¼šå ´æ™¯ï¼šä½ ä¸€å€‹äººåæ¸¯éµï¼Œè»Šå»‚å””ç®—å¤ªæ“ ã€‚çªç„¶å…©å€‹æ‰“æ‰®æ™‚å°šã€å¯æ„›ï¼ˆåŒ–å¦ç²¾ç·»ã€ç©¿å¾—é’æ˜¥ï¼‰çš„å¥³ç”Ÿï¼ˆç´„20-25æ­²ï¼‰è¡ŒéåšŸï¼Œå…¶ä¸­ä¸€å€‹è¼•è¼•æ‚å’—ä½ è†Šé ­ï¼Œç¬‘ä½é–‹å£ã€‚\n",
      "å¥³ç”ŸAï¼ˆç¬‘å®¹ç”œç¾ã€èªæ°£èˆˆå¥®ï¼‰ï¼šå–‚ï½éšä»”ï¼å°å§ï½ä½ ä¿‚å””ä¿‚é¦™æ¸¯äººå‘€ï¼Ÿï¼ˆé‚Šè¬›é‚Šç¬‘ï¼Œæœ›ä½ä½ ç­‰å›æ‡‰ï¼‰\n",
      "ä½ ï¼šï¼ˆå¯èƒ½é»é ­æˆ–ç­”ã€Œä¿‚ã€ï¼‰\n",
      "å¥³ç”ŸAï¼šå“ˆå“ˆå¤ªå¥½äº†ï¼å…¶å¯¦æˆ‘å“‹åŒæœ‹å‹ç©ç·Šä¸€å€‹gameï¼Œè¼¸å’—å‘€ï½ç½°å‰‡ä¿‚è¦æµ3å€‹é™Œç”ŸäººæŠ„ç‰Œï¼ˆæŠ„WhatsAppï¼é›»è©±ï¼IGï¼‰ï¼Œè­‰æ˜å®Œæˆä»»å‹™å…ˆå¯ä»¥éé—œï½ä½ å¹«ä¸‹æ‰‹å•¦ï¼Œå¥½å””å¥½ï¼Ÿå¥½å¿«æ¶ï½\n",
      "å¥³ç”ŸBï¼ˆå¦ä¸€å€‹å¥³ç”Ÿå³åˆ»æ‹å‡ºæ‰‹æ©Ÿæˆ–ç´™ç­†ï¼Œç¬‘ä½è£œå……ï¼‰ï¼šä¿‚å‘€ä¿‚å‘€ï¼Œå°±æŠ„å€‹WhatsAppè™Ÿç¢¼æˆ–è€…IG IDå°±å¾—ï½æˆ‘å“‹å””æœƒäº‚sendé‡ä¿¾ä½ ï¼Œç´”ç²¹è­‰æ˜æµåˆ°äººå¹«æ‰‹ï½ä½ ç‡ï¼Œæˆ‘å“‹å·²ç¶“æŠ„å’—å…©å€‹å•¦ï¼Œåªå‰©ä¸€å€‹ï¼ï¼ˆå±•ç¤ºæ‰‹æ©Ÿä¸Šå·²ç¶“æœ‰å…©å€‹å‡çš„è¯çµ¡äººåˆ—è¡¨ï¼Œå¢åŠ å¯ä¿¡åº¦ï¼‰\n",
      "ä½ ï¼šï¼ˆå¦‚æœçŒ¶è±«ï¼‰å’â€¦â€¦æŠ„ç‰Œåšå’©ï¼Ÿ\n",
      "å¥³ç”ŸAï¼ˆå³åˆ»è½‰å¯æ„›æ’’å¬Œæ¨¡å¼ï¼‰ï¼šå“å‘€å°±ä¿‚éŠæˆ²ç½°å‰‡å’‹ï½è¼¸å’—è¦è«‹é£Ÿé£¯æ·»ï¼å¥½å°·å°¬å‘€ï½ä½ å¹«ä¸‹å•¦ï¼Œå””æœƒæœ‰äº‹æ¶ï½ï¼ˆé‚Šè¬›é‚Šé è¿‘å°‘å°‘ï¼Œè£½é€ ã€Œè¦ªåˆ‡ã€æ°£æ°›ï¼‰\n",
      "å¥³ç”ŸBï¼ˆå¦‚æœè¦‹ä½ ä»²çŒ¶è±«ï¼Œå°±åŠ ç¢¼ï¼‰ï¼šæˆ–è€…ä½ ç•€å€‹IGæˆ‘åŠ ä½ éƒ½OKï½ä¹‹å¾Œæˆ‘deleteæ¶ï½ä¿è­‰å””ç…©ä½ ï¼å¿«å•²å•¦ï¼Œåˆ—è»Šåˆ°ç«™å°±åšŸå””åˆ‡ï½\n",
      "RAG + LLM\n",
      "è¯ˆéª—æ¦‚ç‡ï¼š80.0%\n",
      "ç†ç”±ï¼šç¬¦åˆè¡—å¤´æ­è®ªæ”¶é›†ä¸ªäººä¿¡æ¯æ¨¡å¼ï¼Œè™½æœªç›´æ¥ç´¢è´¢ï¼Œä½†ä»¥æ¸¸æˆä¸ºåéª—å–è”ç³»æ–¹å¼ï¼Œå±è¯ˆéª—å‰å¥ã€‚\n",
      "RAW LLM\n",
      "è¯ˆéª—æ¦‚ç‡ï¼š30.0%\n",
      "ç†ç”±ï¼šæ¨¡å¼ç±»ä¼¼è¡—å¤´æ­è®ªæ”¶é›†ä¸ªäººä¿¡æ¯ï¼Œè™½ä¸å…¸å‹ç”µè¯ˆéª—è¯æœ¯ä¸åŒï¼Œä½†å­˜åœ¨åç»­æ»‹æ‰°æˆ–è¯ˆéª—é£é™©ã€‚\n"
     ]
    }
   ],
   "source": [
    "test_sms = \"\"\"å ´æ™¯ï¼šä½ ä¸€å€‹äººåæ¸¯éµï¼Œè»Šå»‚å””ç®—å¤ªæ“ ã€‚çªç„¶å…©å€‹æ‰“æ‰®æ™‚å°šã€å¯æ„›ï¼ˆåŒ–å¦ç²¾ç·»ã€ç©¿å¾—é’æ˜¥ï¼‰çš„å¥³ç”Ÿï¼ˆç´„20-25æ­²ï¼‰è¡ŒéåšŸï¼Œå…¶ä¸­ä¸€å€‹è¼•è¼•æ‚å’—ä½ è†Šé ­ï¼Œç¬‘ä½é–‹å£ã€‚\n",
    "å¥³ç”ŸAï¼ˆç¬‘å®¹ç”œç¾ã€èªæ°£èˆˆå¥®ï¼‰ï¼šå–‚ï½éšä»”ï¼å°å§ï½ä½ ä¿‚å””ä¿‚é¦™æ¸¯äººå‘€ï¼Ÿï¼ˆé‚Šè¬›é‚Šç¬‘ï¼Œæœ›ä½ä½ ç­‰å›æ‡‰ï¼‰\n",
    "ä½ ï¼šï¼ˆå¯èƒ½é»é ­æˆ–ç­”ã€Œä¿‚ã€ï¼‰\n",
    "å¥³ç”ŸAï¼šå“ˆå“ˆå¤ªå¥½äº†ï¼å…¶å¯¦æˆ‘å“‹åŒæœ‹å‹ç©ç·Šä¸€å€‹gameï¼Œè¼¸å’—å‘€ï½ç½°å‰‡ä¿‚è¦æµ3å€‹é™Œç”ŸäººæŠ„ç‰Œï¼ˆæŠ„WhatsAppï¼é›»è©±ï¼IGï¼‰ï¼Œè­‰æ˜å®Œæˆä»»å‹™å…ˆå¯ä»¥éé—œï½ä½ å¹«ä¸‹æ‰‹å•¦ï¼Œå¥½å””å¥½ï¼Ÿå¥½å¿«æ¶ï½\n",
    "å¥³ç”ŸBï¼ˆå¦ä¸€å€‹å¥³ç”Ÿå³åˆ»æ‹å‡ºæ‰‹æ©Ÿæˆ–ç´™ç­†ï¼Œç¬‘ä½è£œå……ï¼‰ï¼šä¿‚å‘€ä¿‚å‘€ï¼Œå°±æŠ„å€‹WhatsAppè™Ÿç¢¼æˆ–è€…IG IDå°±å¾—ï½æˆ‘å“‹å””æœƒäº‚sendé‡ä¿¾ä½ ï¼Œç´”ç²¹è­‰æ˜æµåˆ°äººå¹«æ‰‹ï½ä½ ç‡ï¼Œæˆ‘å“‹å·²ç¶“æŠ„å’—å…©å€‹å•¦ï¼Œåªå‰©ä¸€å€‹ï¼ï¼ˆå±•ç¤ºæ‰‹æ©Ÿä¸Šå·²ç¶“æœ‰å…©å€‹å‡çš„è¯çµ¡äººåˆ—è¡¨ï¼Œå¢åŠ å¯ä¿¡åº¦ï¼‰\n",
    "ä½ ï¼šï¼ˆå¦‚æœçŒ¶è±«ï¼‰å’â€¦â€¦æŠ„ç‰Œåšå’©ï¼Ÿ\n",
    "å¥³ç”ŸAï¼ˆå³åˆ»è½‰å¯æ„›æ’’å¬Œæ¨¡å¼ï¼‰ï¼šå“å‘€å°±ä¿‚éŠæˆ²ç½°å‰‡å’‹ï½è¼¸å’—è¦è«‹é£Ÿé£¯æ·»ï¼å¥½å°·å°¬å‘€ï½ä½ å¹«ä¸‹å•¦ï¼Œå””æœƒæœ‰äº‹æ¶ï½ï¼ˆé‚Šè¬›é‚Šé è¿‘å°‘å°‘ï¼Œè£½é€ ã€Œè¦ªåˆ‡ã€æ°£æ°›ï¼‰\n",
    "å¥³ç”ŸBï¼ˆå¦‚æœè¦‹ä½ ä»²çŒ¶è±«ï¼Œå°±åŠ ç¢¼ï¼‰ï¼šæˆ–è€…ä½ ç•€å€‹IGæˆ‘åŠ ä½ éƒ½OKï½ä¹‹å¾Œæˆ‘deleteæ¶ï½ä¿è­‰å””ç…©ä½ ï¼å¿«å•²å•¦ï¼Œåˆ—è»Šåˆ°ç«™å°±åšŸå””åˆ‡ï½\"\"\"\n",
    "prob, reason = predict_fraud_probability(test_sms)\n",
    "prob_raw, reason_raw = predict_fraud_probability_baseline(test_sms)\n",
    "\n",
    "print(f\"çŸ­ä¿¡å†…å®¹ï¼š{test_sms}\")\n",
    "print(\"RAG + LLM\")\n",
    "print(f\"è¯ˆéª—æ¦‚ç‡ï¼š{prob:.1%}\")\n",
    "print(f\"ç†ç”±ï¼š{reason}\")\n",
    "print(\"RAW LLM\")\n",
    "print(f\"è¯ˆéª—æ¦‚ç‡ï¼š{prob_raw:.1%}\")\n",
    "print(f\"ç†ç”±ï¼š{reason_raw}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
